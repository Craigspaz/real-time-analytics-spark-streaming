{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27aaf7af-e0bd-4127-b81c-1f7891ec2ef6",
   "metadata": {},
   "source": [
    "# Test Notebook - Write to S3\n",
    "A notebook to test a simple write to an Amazon S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72291c8-8316-459a-bf5e-2b633f391f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime, date\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "output_path = \"s3://analytics-with-emr-<your AWS Account ID>/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448aab7e-a961-42c6-b68c-4107053e7df4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# schema creation by passing list\n",
    "df = spark.createDataFrame([\n",
    "    Row(a=1, b=4., c='GFG1', d=date(2000, 8, 1),\n",
    "        e=datetime(2000, 8, 1, 12, 0)),\n",
    "   \n",
    "    Row(a=2, b=8., c='GFG2', d=date(2000, 6, 2), \n",
    "        e=datetime(2000, 6, 2, 12, 0)),\n",
    "   \n",
    "    Row(a=4, b=5., c='GFG3', d=date(2000, 5, 3),\n",
    "        e=datetime(2000, 5, 3, 12, 0))\n",
    "])\n",
    " \n",
    "# show table\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3940c9-794b-4c04-8207-91f389036daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").json(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125c97be-0cdd-4730-a2ca-f74146dc40fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
